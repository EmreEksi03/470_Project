{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from meta_learning_custom_3 import DatasetLoader, MetaFeatureExtractor, AlgorithmSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_saved_meta_model(datasets_folder):\n",
    "    # Load trained model and scaler\n",
    "    model = joblib.load(\"meta_classifier.pkl\")\n",
    "    scaler = joblib.load(\"meta_scaler.pkl\")\n",
    "\n",
    "    # Initialize components\n",
    "    loader = DatasetLoader(datasets_folder)\n",
    "    extractor = MetaFeatureExtractor()\n",
    "    selector = AlgorithmSelector()  # For evaluating actual best algorithm\n",
    "\n",
    "    datasets = loader.load_datasets_from_folder()\n",
    "    if not datasets:\n",
    "        print(\"No datasets found or loaded.\")\n",
    "        return\n",
    "\n",
    "    correct_top1 = 0\n",
    "    correct_top3 = 0\n",
    "    total = 0\n",
    "    prediction_distribution = {}\n",
    "\n",
    "    print(\"\\n=== Meta-Model Evaluation ===\")\n",
    "\n",
    "    for X, y, name in datasets:\n",
    "        try:\n",
    "            # Extract meta-features\n",
    "            meta_features = extractor.extract_meta_features(X, y)\n",
    "            meta_array = np.array([list(meta_features.values())])\n",
    "            meta_array = np.nan_to_num(meta_array, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "            meta_scaled = scaler.transform(meta_array)\n",
    "\n",
    "            # Meta-model prediction\n",
    "            predicted = model.predict(meta_scaled)[0]\n",
    "            probabilities = model.predict_proba(meta_scaled)[0]\n",
    "            classes = model.classes_\n",
    "\n",
    "            # Top-3 predictions\n",
    "            top3_indices = np.argsort(probabilities)[::-1][:3]\n",
    "            top3_preds = [classes[i] for i in top3_indices]\n",
    "\n",
    "            # Actual best algorithm\n",
    "            actual, _ = selector.find_best_algorithm(X, y)\n",
    "\n",
    "            print(f\"{name}: Predicted = {predicted}, Actual = {actual}\")\n",
    "            print(\"  Top-3:\", \", \".join(f\"{alg} ({probabilities[i]:.2f})\" for i, alg in zip(top3_indices, top3_preds)))\n",
    "\n",
    "            if predicted == actual:\n",
    "                correct_top1 += 1\n",
    "            if actual in top3_preds:\n",
    "                correct_top3 += 1\n",
    "\n",
    "            prediction_distribution[predicted] = prediction_distribution.get(predicted, 0) + 1\n",
    "            total += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {name}: {e}\")\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\nTop-1 Accuracy: {correct_top1}/{total} = {correct_top1 / total:.4f}\")\n",
    "    print(f\"Top-3 Accuracy: {correct_top3}/{total} = {correct_top3 / total:.4f}\")\n",
    "\n",
    "    print(\"\\nMeta-Model Prediction Distribution:\")\n",
    "    for alg, count in prediction_distribution.items():\n",
    "        print(f\"  {alg}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 CSV files\n",
      "Loading dataset: adult\n",
      "  ✓ Successfully loaded: 32560 samples, 14 features, 2 classes\n",
      "Loading dataset: car\n",
      "  ✓ Successfully loaded: 1727 samples, 6 features, 4 classes\n",
      "Loading dataset: iris\n",
      "  ✓ Successfully loaded: 149 samples, 4 features, 3 classes\n",
      "Loading dataset: wdbc\n",
      "  ✓ Successfully loaded: 568 samples, 31 features, 2 classes\n",
      "Loading dataset: winequality-red\n",
      "  ✓ Successfully loaded: 1599 samples, 11 features, 6 classes\n",
      "Loading dataset: winequality-white\n",
      "  ✓ Successfully loaded: 4898 samples, 11 features, 7 classes\n",
      "\n",
      "Successfully loaded 6 out of 6 datasets\n",
      "\n",
      "=== Meta-Model Evaluation ===\n",
      "adult: Predicted = LogisticRegression, Actual = XGBoost\n",
      "  Top-3: LogisticRegression (0.68), RandomForest (0.32), XGBoost (0.00)\n",
      "car: Predicted = LogisticRegression, Actual = RandomForest\n",
      "  Top-3: LogisticRegression (0.43), RandomForest (0.36), SVM (0.16)\n",
      "iris: Predicted = RandomForest, Actual = LogisticRegression\n",
      "  Top-3: RandomForest (0.98), SVM (0.02), XGBoost (0.00)\n",
      "wdbc: Predicted = SVM, Actual = XGBoost\n",
      "  Top-3: SVM (0.41), RandomForest (0.31), KNN (0.13)\n",
      "winequality-red: Predicted = RandomForest, Actual = LogisticRegression\n",
      "  Top-3: RandomForest (1.00), XGBoost (0.00), SVM (0.00)\n",
      "winequality-white: Predicted = RandomForest, Actual = RandomForest\n",
      "  Top-3: RandomForest (0.95), XGBoost (0.05), SVM (0.00)\n",
      "\n",
      "Top-1 Accuracy: 1/6 = 0.1667\n",
      "Top-3 Accuracy: 3/6 = 0.5000\n",
      "\n",
      "Meta-Model Prediction Distribution:\n",
      "  LogisticRegression: 2 times\n",
      "  RandomForest: 3 times\n",
      "  SVM: 1 times\n"
     ]
    }
   ],
   "source": [
    "folder = \"testing_datasets\"  # Replace with your actual dataset folder\n",
    "evaluate_saved_meta_model(folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
